[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.










































































































































































 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 171/256 [09:23<04:40,  3.30s/it]
Traceback (most recent call last):
  File "/home/zinzinbin/codes_for_study/RL/RL-study/DQN-Atari/train_dqn.py", line 192, in <module>
    reward_new, loss_new = optimize_model()
  File "/home/zinzinbin/codes_for_study/RL/RL-study/DQN-Atari/train_dqn.py", line 121, in optimize_model
    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()
  File "/home/zinzinbin/.conda/envs/rl-env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/zinzinbin/codes_for_study/RL/RL-study/DQN-Atari/src/model.py", line 33, in forward
    x = nn.functional.relu(self.bn1(self.conv1(x)))
  File "/home/zinzinbin/.conda/envs/rl-env/lib/python3.9/site-packages/torch/nn/functional.py", line 1299, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.91 GiB total capacity; 10.11 GiB already allocated; 21.94 MiB free; 10.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF